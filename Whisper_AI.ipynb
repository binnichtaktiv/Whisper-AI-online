{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO8NXmrg1nVJIWjaEOuxkEc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/binnichtaktiv/Whisper-AI-online/blob/main/Whisper_AI.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8QZ8J7szoIZs",
        "outputId": "0a21c624-0cce-4f11-b638-477a6eb6fdaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-otb41cpa\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-otb41cpa\n",
            "  Resolved https://github.com/openai/whisper.git to commit c09a7ae299c4c34c5839a76380ae407e7d785914\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (1.22.4)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (2.0.0+cu118)\n",
            "Collecting tiktoken==0.3.1\n",
            "  Downloading tiktoken-0.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: more-itertools in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (9.1.0)\n",
            "Collecting ffmpeg-python==0.2.0\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (4.65.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.9/dist-packages (from openai-whisper==20230314) (0.56.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.9/dist-packages (from ffmpeg-python==0.2.0->openai-whisper==20230314) (0.18.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2.27.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.9/dist-packages (from tiktoken==0.3.1->openai-whisper==20230314) (2022.10.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.11.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->openai-whisper==20230314) (16.0.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (67.6.1)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba->openai-whisper==20230314) (0.39.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (4.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->openai-whisper==20230314) (3.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.26.0->tiktoken==0.3.1->openai-whisper==20230314) (1.26.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->openai-whisper==20230314) (2.1.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->openai-whisper==20230314) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20230314-py3-none-any.whl size=798038 sha256=d9c56d183e2a81c111e311b4eadb8e0c8367504c3758427740686761cec5a423\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-eqqlwb20/wheels/fe/03/29/e7919208d11b4ab32972cb448bb84a9a675d92cd52c9a48341\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: ffmpeg-python, tiktoken, openai-whisper\n",
            "Successfully installed ffmpeg-python-0.2.0 openai-whisper-20230314 tiktoken-0.3.1\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [975 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Hit:9 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:10 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,029 kB]\n",
            "Hit:11 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:13 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:14 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,075 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,593 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,325 kB]\n",
            "Fetched 9,338 kB in 3s (2,724 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "24 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.2.7-0ubuntu0.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 24 not upgraded.\n"
          ]
        }
      ],
      "source": [
        " !pip install git+https://github.com/openai/whisper.git\n",
        " !sudo apt update && sudo apt install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"test.mp3\" --model medium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzPfmjPKou5R",
        "outputId": "ef2cc7db-7c34-49fa-b9e5-e28e0bbda537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████████████████████████████████| 1.42G/1.42G [00:05<00:00, 263MiB/s]\n",
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:05.400]  I want to start off by saying that I know I have an accent and please don't\n",
            "[00:05.400 --> 00:09.720]  assume it's Russian. More and more people are complaining about the Go Transcript\n",
            "[00:09.720 --> 00:14.360]  test, about our rules, about the low acceptance rates and to be honest I've\n",
            "[00:14.360 --> 00:20.080]  pretty much had it with all this whining. First of all, the tests we've\n",
            "[00:20.080 --> 00:25.760]  had so far were easy. All you had to do is listen carefully, read our guidelines\n",
            "[00:25.760 --> 00:31.280]  and do some research. These things are in the job description. Our clients don't\n",
            "[00:31.280 --> 00:36.280]  always have good quality files, some may have background noise, some might be in a\n",
            "[00:36.280 --> 00:40.520]  difficult accent, some might contain terms you've never heard of, but we have\n",
            "[00:40.520 --> 00:46.800]  to provide 98-99% accuracy for all of our clients. We've tried to make sure\n",
            "[00:46.800 --> 00:51.640]  that our communication with employees and employers is a good one. We're\n",
            "[00:51.640 --> 00:57.400]  available on Facebook, Skype, live support, email, phone. We answer all kinds of\n",
            "[00:57.400 --> 01:03.200]  questions regardless of how redundant they are or in some cases even rude. We\n",
            "[01:03.200 --> 01:08.580]  have at least four ways of explaining how everything works. We tweak to the way\n",
            "[01:08.580 --> 01:13.640]  we communicate information over and over again in the hope that it'd be clear for\n",
            "[01:13.640 --> 01:19.480]  everyone and yet it's not. We're not one of those cold-hearted companies that\n",
            "[01:19.520 --> 01:24.160]  doesn't give a fuck about its employees. We work with people on a personal level,\n",
            "[01:24.160 --> 01:28.720]  which is why it's so frustrating for us to see duplicated tests or account\n",
            "[01:28.720 --> 01:34.560]  selling happening on GT. These things are so disrespectful I can't even begin to\n",
            "[01:34.560 --> 01:40.600]  say, you know what, it's wrong on so many levels. I'm not over dramatic and I'm not\n",
            "[01:40.600 --> 01:45.800]  overreacting. These things happen and we can't allow these kinds of behaviors\n",
            "[01:45.800 --> 01:51.360]  within our company. You know what, let me tell you a little story. Only three\n",
            "[01:51.360 --> 01:57.040]  years ago this company got like three or four orders per week, small ones. We were\n",
            "[01:57.040 --> 02:02.840]  a handful of transcribers and we didn't have editors. And look where we are now.\n",
            "[02:02.840 --> 02:07.520]  For someone who comes to us for the first time they think like this site\n",
            "[02:07.520 --> 02:13.360]  always looked like this, this always had this many orders, they always had these\n",
            "[02:13.360 --> 02:22.080]  rules, this system in place, all of our services and nobody had to really work\n",
            "[02:22.080 --> 02:26.760]  hard to get where they are now. Well that's bullshit. We worked our asses off.\n",
            "[02:26.760 --> 02:32.280]  All you see here today has been done by a programmer and two jacks of all trades.\n",
            "[02:32.280 --> 02:37.160]  We worked day in and day out. We didn't have time off for months. We added\n",
            "[02:37.160 --> 02:41.640]  something new every day. We did research, we advertised, we risked all of our\n",
            "[02:41.640 --> 02:47.040]  savings for the company and it paid out. Now we got from 20 or less transcribers\n",
            "[02:47.040 --> 02:54.600]  to 2,000. We have over 500 editors. We hire all the time. We don't turn anyone\n",
            "[02:54.600 --> 03:00.960]  down when they're asking for a chance. But what they do with that chance is up\n",
            "[03:00.960 --> 03:03.360]  to them.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "WPDrSe4dq8BV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper \"1.mp3\" --model medium"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeVXgancq9a5",
        "outputId": "01335236-40ae-4b28-f2cf-6fec40ff4d27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: English\n",
            "[00:00.000 --> 00:05.000]  This audio is used for the transcriber test at GoTranscript.\n",
            "[00:05.000 --> 00:13.000]  Hi, so I just ordered a bunch of stuff from Amazon and I was just going to go look through my orders.\n",
            "[00:13.000 --> 00:20.000]  Because honestly, sometimes I feel like I spend too much money on stuff that I wind up later not needing at all.\n",
            "[00:20.000 --> 00:30.000]  So one of the things that I ordered was this Bluetooth adapter that's supposed to make it easier for me to play music in my car.\n",
            "[00:30.000 --> 00:36.000]  Because see, I have this really old car and the CD player stopped working.\n",
            "[00:36.000 --> 00:44.000]  So I was thinking about either getting a new CD player or getting a new car actually.\n",
            "[00:44.000 --> 00:49.000]  I was kind of debating a new car, but unfortunately I just don't have the money for that.\n",
            "[00:49.000 --> 00:57.000]  Because even a down payment on a car that I could afford would be at least $1,500 and I just don't have that.\n",
            "[00:57.000 --> 01:07.000]  So here's what I came up with. I came up with this Bluetooth FM transmitter that's like a car adapter that you stick in the cigarette lighter.\n",
            "[01:07.000 --> 01:11.000]  I've never tried one before, so I'm kind of interested to see if it works.\n",
            "[01:11.000 --> 01:19.000]  And then I bought a bunch of USB flash drives, like a five pack. Each of them is four gigabytes. They're like thumb drives.\n",
            "[01:19.000 --> 01:27.000]  And they're really cute, the ones I ordered, because they're multiple colors. They're black and blue and pink and orange and green.\n",
            "[01:27.000 --> 01:32.000]  So I thought that might make it easier for me to figure out which is which.\n",
            "[01:32.000 --> 01:39.000]  Because I know they have a lot of capability on them, but I think I'm going to just put different types of music on each one.\n",
            "[01:39.000 --> 01:48.000]  So that when I'm in my car and I'm in the mood to listen to Weird Al Yankovic, I can just pull out the orange one.\n",
            "[01:48.000 --> 01:54.000]  I think I'll make orange Weird Al's color, because I like Weird Al anyway.\n",
            "[01:54.000 --> 01:58.000]  I don't know if you've ever heard him, but he plays the accordion and he writes parodies of songs.\n",
            "[01:58.000 --> 02:03.000]  And he's been around since the 90s or maybe the 80s. I don't know.\n",
            "[02:03.000 --> 02:12.000]  But anyway, so I'll have Weird Al and then I'll have some sentimental crap like Enya and John Denver and stuff like that on another one.\n",
            "[02:12.000 --> 02:16.000]  And you know, you can see what I'm talking about, right?\n",
            "[02:16.000 --> 02:23.000]  So then on a completely different note, I ordered this deshedding tool for my cat.\n",
            "[02:23.000 --> 02:32.000]  See, we have two cats and one of them has just super long hair and he's always getting fleas and stuff in the fur and we give him flea treatments.\n",
            "[02:32.000 --> 02:35.000]  But because he's indoor-outdoor, he still gets fleas.\n",
            "[02:35.000 --> 02:43.000]  So this is called the Furminator 1073-0. It's a long hair deshedding tool for cats.\n",
            "[02:43.000 --> 02:47.000]  And Furminator is the name of it like Terminator, only fur instead.\n",
            "[02:47.000 --> 02:57.000]  So my vet recommended it, so I'm going to give it a try and see if it helps our cat to feel a little better this summer.\n",
            "[02:57.000 --> 03:00.000]  And then this is something completely different.\n",
            "[03:00.000 --> 03:09.000]  See, I've been making popcorn at home, but the problem is with popcorn, it really doesn't taste that good to me unless it's got hot melted butter on it.\n",
            "[03:09.000 --> 03:17.000]  But hot melted butter just adds tons of calories and fat to your popcorn and the whole idea is for it to be like a diet food, right?\n",
            "[03:17.000 --> 03:24.000]  So I was reading online that there's a way to take a smaller amount of butter and mix it somehow with water.\n",
            "[03:24.000 --> 03:26.000]  I don't know. I'm going to have to look at the videos.\n",
            "[03:26.000 --> 03:37.000]  But you put it in a spray bottle and then you can just spray a little bit on your popcorn and then sprinkle some other flavorings like ranch dressing powder or something like that.\n",
            "[03:37.000 --> 03:46.000]  And I already use the ranch dressing powder and sometimes if I want it to be sweet, instead I'll use cinnamon sugar or something like that.\n",
            "[03:46.000 --> 03:51.000]  But if the popcorn is dry, it just all seems to fall to the bottom of the bowl.\n",
            "[03:51.000 --> 03:54.000]  So I'm interested to see how that'll work.\n",
            "[03:54.000 --> 03:59.000]  This audio is used for the transcriber test at GoTranscript.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!whisper --help\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7oeMMMgpkbn",
        "outputId": "8468299d-436a-4c01-fa8b-e648a2f76fb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: whisper\n",
            "       [-h]\n",
            "       [--model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}]\n",
            "       [--model_dir MODEL_DIR]\n",
            "       [--device DEVICE]\n",
            "       [--output_dir OUTPUT_DIR]\n",
            "       [--output_format {txt,vtt,srt,tsv,json,all}]\n",
            "       [--verbose VERBOSE]\n",
            "       [--task {transcribe,translate}]\n",
            "       [--language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}]\n",
            "       [--temperature TEMPERATURE]\n",
            "       [--best_of BEST_OF]\n",
            "       [--beam_size BEAM_SIZE]\n",
            "       [--patience PATIENCE]\n",
            "       [--length_penalty LENGTH_PENALTY]\n",
            "       [--suppress_tokens SUPPRESS_TOKENS]\n",
            "       [--initial_prompt INITIAL_PROMPT]\n",
            "       [--condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT]\n",
            "       [--fp16 FP16]\n",
            "       [--temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK]\n",
            "       [--compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD]\n",
            "       [--logprob_threshold LOGPROB_THRESHOLD]\n",
            "       [--no_speech_threshold NO_SPEECH_THRESHOLD]\n",
            "       [--word_timestamps WORD_TIMESTAMPS]\n",
            "       [--prepend_punctuations PREPEND_PUNCTUATIONS]\n",
            "       [--append_punctuations APPEND_PUNCTUATIONS]\n",
            "       [--highlight_words HIGHLIGHT_WORDS]\n",
            "       [--max_line_width MAX_LINE_WIDTH]\n",
            "       [--max_line_count MAX_LINE_COUNT]\n",
            "       [--threads THREADS]\n",
            "       audio\n",
            "       [audio ...]\n",
            "\n",
            "positional arguments:\n",
            "  audio\n",
            "    audio\n",
            "    file(s) to\n",
            "    transcribe\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help\n",
            "    show this\n",
            "    help\n",
            "    message and\n",
            "    exit\n",
            "  --model {tiny.en,tiny,base.en,base,small.en,small,medium.en,medium,large-v1,large-v2,large}\n",
            "    name of the\n",
            "    Whisper\n",
            "    model to\n",
            "    use\n",
            "    (default:\n",
            "    small)\n",
            "  --model_dir MODEL_DIR\n",
            "    the path to\n",
            "    save model\n",
            "    files; uses\n",
            "    ~/.cache/wh\n",
            "    isper by\n",
            "    default\n",
            "    (default:\n",
            "    None)\n",
            "  --device DEVICE\n",
            "    device to\n",
            "    use for\n",
            "    PyTorch\n",
            "    inference\n",
            "    (default:\n",
            "    cuda)\n",
            "  --output_dir OUTPUT_DIR, -o OUTPUT_DIR\n",
            "    directory\n",
            "    to save the\n",
            "    outputs\n",
            "    (default:\n",
            "    .)\n",
            "  --output_format {txt,vtt,srt,tsv,json,all}, -f {txt,vtt,srt,tsv,json,all}\n",
            "    format of\n",
            "    the output\n",
            "    file; if\n",
            "    not\n",
            "    specified,\n",
            "    all\n",
            "    available\n",
            "    formats\n",
            "    will be\n",
            "    produced\n",
            "    (default:\n",
            "    all)\n",
            "  --verbose VERBOSE\n",
            "    whether to\n",
            "    print out\n",
            "    the\n",
            "    progress\n",
            "    and debug\n",
            "    messages\n",
            "    (default:\n",
            "    True)\n",
            "  --task {transcribe,translate}\n",
            "    whether to\n",
            "    perform\n",
            "    X->X speech\n",
            "    recognition\n",
            "    ('transcrib\n",
            "    e') or\n",
            "    X->English\n",
            "    translation\n",
            "    ('translate\n",
            "    ')\n",
            "    (default:\n",
            "    transcribe)\n",
            "  --language {af,am,ar,as,az,ba,be,bg,bn,bo,br,bs,ca,cs,cy,da,de,el,en,es,et,eu,fa,fi,fo,fr,gl,gu,ha,haw,he,hi,hr,ht,hu,hy,id,is,it,ja,jw,ka,kk,km,kn,ko,la,lb,ln,lo,lt,lv,mg,mi,mk,ml,mn,mr,ms,mt,my,ne,nl,nn,no,oc,pa,pl,ps,pt,ro,ru,sa,sd,si,sk,sl,sn,so,sq,sr,su,sv,sw,ta,te,tg,th,tk,tl,tr,tt,uk,ur,uz,vi,yi,yo,zh,Afrikaans,Albanian,Amharic,Arabic,Armenian,Assamese,Azerbaijani,Bashkir,Basque,Belarusian,Bengali,Bosnian,Breton,Bulgarian,Burmese,Castilian,Catalan,Chinese,Croatian,Czech,Danish,Dutch,English,Estonian,Faroese,Finnish,Flemish,French,Galician,Georgian,German,Greek,Gujarati,Haitian,Haitian Creole,Hausa,Hawaiian,Hebrew,Hindi,Hungarian,Icelandic,Indonesian,Italian,Japanese,Javanese,Kannada,Kazakh,Khmer,Korean,Lao,Latin,Latvian,Letzeburgesch,Lingala,Lithuanian,Luxembourgish,Macedonian,Malagasy,Malay,Malayalam,Maltese,Maori,Marathi,Moldavian,Moldovan,Mongolian,Myanmar,Nepali,Norwegian,Nynorsk,Occitan,Panjabi,Pashto,Persian,Polish,Portuguese,Punjabi,Pushto,Romanian,Russian,Sanskrit,Serbian,Shona,Sindhi,Sinhala,Sinhalese,Slovak,Slovenian,Somali,Spanish,Sundanese,Swahili,Swedish,Tagalog,Tajik,Tamil,Tatar,Telugu,Thai,Tibetan,Turkish,Turkmen,Ukrainian,Urdu,Uzbek,Valencian,Vietnamese,Welsh,Yiddish,Yoruba}\n",
            "    language\n",
            "    spoken in\n",
            "    the audio,\n",
            "    specify\n",
            "    None to\n",
            "    perform\n",
            "    language\n",
            "    detection\n",
            "    (default:\n",
            "    None)\n",
            "  --temperature TEMPERATURE\n",
            "    temperature\n",
            "    to use for\n",
            "    sampling\n",
            "    (default:\n",
            "    0)\n",
            "  --best_of BEST_OF\n",
            "    number of\n",
            "    candidates\n",
            "    when\n",
            "    sampling\n",
            "    with non-\n",
            "    zero\n",
            "    temperature\n",
            "    (default:\n",
            "    5)\n",
            "  --beam_size BEAM_SIZE\n",
            "    number of\n",
            "    beams in\n",
            "    beam\n",
            "    search,\n",
            "    only\n",
            "    applicable\n",
            "    when\n",
            "    temperature\n",
            "    is zero\n",
            "    (default:\n",
            "    5)\n",
            "  --patience PATIENCE\n",
            "    optional\n",
            "    patience\n",
            "    value to\n",
            "    use in beam\n",
            "    decoding,\n",
            "    as in https\n",
            "    ://arxiv.or\n",
            "    g/abs/2204.\n",
            "    05424, the\n",
            "    default\n",
            "    (1.0) is\n",
            "    equivalent\n",
            "    to conventi\n",
            "    onal beam\n",
            "    search\n",
            "    (default:\n",
            "    None)\n",
            "  --length_penalty LENGTH_PENALTY\n",
            "    optional\n",
            "    token\n",
            "    length\n",
            "    penalty\n",
            "    coefficient\n",
            "    (alpha) as\n",
            "    in https://\n",
            "    arxiv.org/a\n",
            "    bs/1609.081\n",
            "    44, uses\n",
            "    simple\n",
            "    length norm\n",
            "    alization\n",
            "    by default\n",
            "    (default:\n",
            "    None)\n",
            "  --suppress_tokens SUPPRESS_TOKENS\n",
            "    comma-\n",
            "    separated\n",
            "    list of\n",
            "    token ids\n",
            "    to suppress\n",
            "    during\n",
            "    sampling;\n",
            "    '-1' will\n",
            "    suppress\n",
            "    most\n",
            "    special\n",
            "    characters\n",
            "    except\n",
            "    common punc\n",
            "    tuations\n",
            "    (default:\n",
            "    -1)\n",
            "  --initial_prompt INITIAL_PROMPT\n",
            "    optional\n",
            "    text to\n",
            "    provide as\n",
            "    a prompt\n",
            "    for the\n",
            "    first\n",
            "    window.\n",
            "    (default:\n",
            "    None)\n",
            "  --condition_on_previous_text CONDITION_ON_PREVIOUS_TEXT\n",
            "    if True,\n",
            "    provide the\n",
            "    previous\n",
            "    output of\n",
            "    the model\n",
            "    as a prompt\n",
            "    for the\n",
            "    next\n",
            "    window;\n",
            "    disabling\n",
            "    may make\n",
            "    the text in\n",
            "    consistent\n",
            "    across\n",
            "    windows,\n",
            "    but the\n",
            "    model\n",
            "    becomes\n",
            "    less prone\n",
            "    to getting\n",
            "    stuck in a\n",
            "    failure\n",
            "    loop\n",
            "    (default:\n",
            "    True)\n",
            "  --fp16 FP16\n",
            "    whether to\n",
            "    perform\n",
            "    inference\n",
            "    in fp16;\n",
            "    True by\n",
            "    default\n",
            "    (default:\n",
            "    True)\n",
            "  --temperature_increment_on_fallback TEMPERATURE_INCREMENT_ON_FALLBACK\n",
            "    temperature\n",
            "    to increase\n",
            "    when\n",
            "    falling\n",
            "    back when\n",
            "    the\n",
            "    decoding\n",
            "    fails to\n",
            "    meet either\n",
            "    of the\n",
            "    thresholds\n",
            "    below\n",
            "    (default:\n",
            "    0.2)\n",
            "  --compression_ratio_threshold COMPRESSION_RATIO_THRESHOLD\n",
            "    if the gzip\n",
            "    compression\n",
            "    ratio is\n",
            "    higher than\n",
            "    this value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    2.4)\n",
            "  --logprob_threshold LOGPROB_THRESHOLD\n",
            "    if the\n",
            "    average log\n",
            "    probability\n",
            "    is lower\n",
            "    than this\n",
            "    value,\n",
            "    treat the\n",
            "    decoding as\n",
            "    failed\n",
            "    (default:\n",
            "    -1.0)\n",
            "  --no_speech_threshold NO_SPEECH_THRESHOLD\n",
            "    if the\n",
            "    probability\n",
            "    of the <|no\n",
            "    speech|>\n",
            "    token is\n",
            "    higher than\n",
            "    this value\n",
            "    AND the\n",
            "    decoding\n",
            "    has failed\n",
            "    due to `log\n",
            "    prob_thresh\n",
            "    old`,\n",
            "    consider\n",
            "    the segment\n",
            "    as silence\n",
            "    (default:\n",
            "    0.6)\n",
            "  --word_timestamps WORD_TIMESTAMPS\n",
            "    (experiment\n",
            "    al) extract\n",
            "    word-level\n",
            "    timestamps\n",
            "    and refine\n",
            "    the results\n",
            "    based on\n",
            "    them\n",
            "    (default:\n",
            "    False)\n",
            "  --prepend_punctuations PREPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    next word\n",
            "    (default:\n",
            "    \"'“¿([{-)\n",
            "  --append_punctuations APPEND_PUNCTUATIONS\n",
            "    if word_tim\n",
            "    estamps is\n",
            "    True, merge\n",
            "    these\n",
            "    punctuation\n",
            "    symbols\n",
            "    with the\n",
            "    previous\n",
            "    word\n",
            "    (default: \"\n",
            "    '.。,，!！?？:：\n",
            "    ”)]}、)\n",
            "  --highlight_words HIGHLIGHT_WORDS\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    underline\n",
            "    each word\n",
            "    as it is\n",
            "    spoken in\n",
            "    srt and vtt\n",
            "    (default:\n",
            "    False)\n",
            "  --max_line_width MAX_LINE_WIDTH\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    characters\n",
            "    in a line\n",
            "    before\n",
            "    breaking\n",
            "    the line\n",
            "    (default:\n",
            "    None)\n",
            "  --max_line_count MAX_LINE_COUNT\n",
            "    (requires -\n",
            "    -word_times\n",
            "    tamps True)\n",
            "    the maximum\n",
            "    number of\n",
            "    lines in a\n",
            "    segment\n",
            "    (default:\n",
            "    None)\n",
            "  --threads THREADS\n",
            "    number of\n",
            "    threads\n",
            "    used by\n",
            "    torch for\n",
            "    CPU\n",
            "    inference;\n",
            "    supercedes \n",
            "    MKL_NUM_THR\n",
            "    EADS/OMP_NU\n",
            "    M_THREADS\n",
            "    (default:\n",
            "    0)\n"
          ]
        }
      ]
    }
  ]
}